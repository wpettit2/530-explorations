---
title: 'Exploration 6: Engaging with Alternative Explanations with By Matched Stratification'
author: 'Jake Bowers'
date: '`r format(Sys.Date(), "%B %d, %Y")`'
bibliography: classbib.bib
fontsize: 10pt
geometry: margin=1in
mainfont: "Crimson Text"
graphics: yes
output:
  html_document:
    fig_caption: yes
    fig_height: 4
    fig_width: 4
  pdf_document:
    latex_engine: xelatex
    fig_caption: yes
    fig_height: 4
    fig_width: 4
---

<!-- Make this document using library(rmarkdown); render("exploration1.Rmd") -->
\input{mytexsymbols}


```{r include=FALSE, cache=FALSE}
# Some customization.  You can alter or delete as desired (if you know what you are doing).
# knitr settings to control how R chunks work.

## To make the html file do
## render("exploration1.Rmd",output_format=html_document(fig_retina=FALSE))
## To make the pdf file do
## render("exploration1.Rmd",output_format=pdf_document())

require(knitr)
opts_chunk$set(
  tidy=FALSE,     # display code as typed
  size="small",    # slightly smaller font for code
  echo=TRUE,
  results='markup',
  strip.white=TRUE,
  fig.path='figs/fig',
  cache=FALSE,
  highlight=TRUE,
  width.cutoff=132,
  size='footnotesize',
  out.width='.9\\textwidth',
  fig.retina=FALSE,
  message=FALSE,
  comment=NA)

if(!file.exists('figs')) dir.create('figs')

options(SweaveHooks=list(fig=function(){
			   par(mar=c(3.5, 3, 1.1, 0),
			       pty="s",
			       mgp=c(1.5,0.5,0),
			       oma=c(0,0,0,0))},
			 echo=function(){options(continue=" ") ##Don't show "+" prompts,
			 options(prompt=" ")
			 }),
	digits=4,
	scipen=8,
	width=132
	)
options(error=function(){options(prompt="> ",continue="+ ");NULL})
```

"Hey data scientist!" The voice on the phone is chipper. "I am involved in a
~~hearts and minds~~ anti-crime campaign for the peaceful and helpful United
Nations now. I ran across this dataset and thought that it might teach me
about whether I should fund public transportation to be ~~re~~built in order
to decrease violence. I'm sending you the description and the code. I just
can't get the code to work at all. Also, even if I could get it to work, I
wouldn't know how to interpret any of it. Can you please help? Does
infrastructure investment like this seem to decrease violence? Or produce
other social goods? Here is what I found out."

> In 2004 the municipality of Medell\'{i}n, Columbia built built the first line
 of the Metrocable --- a set of cable cars that connected poor neighborhoods
 on the edges of the city to the center of the city \citep{cerda2012reducing}.
 Professor Magdalena Cerd\'{a} and her collaborators asked whether this kind
 of integration could improve life in these poor (and heretofore violent)
 neighborhoods. We ~~extracted~~ were given some of the data from this project to use
 here.\footnote{The articles can be both found in this web directory
 \url{http://jakebowers.org/Matching/}.}

```{r}
library(MASS)
library(RItools)
library(optmatch)
load(url("http://jakebowers.org/Data/meddat.rda"))
```


> The data Cerd\'{a} collected tell us about the roughly `r nrow(meddat)`
neighborhoods in the study, `r signif(sum(meddat$nhTrt),2)` of which had
access to the Metrocable line and `r signif(sum(1-meddat$nhTrt),2)` did not.

> We don't have a formal codebook. Here are some guesses about the meanings of
some of the variables. There are more variables in the data file than those
listed here.

```
## The Intervention
nhTrt        Intervention neighborhood (0=no Metrocable station, 1=Metrocable station)

## Some Covariates (there are others, see the paper itself)
nh03         Neighborhood id
nhGroup      Treatment (T) or Control (C)
nhTrt        Treatment (1) or Control (0)
nhHom        Mean homicide rate per 100,000 population in 2003
nhDistCenter Distance to city center (km)
nhLogHom     Log Homicide (i.e. log(nhHom))

## Outcomes (BE03,CE03,PV03,QP03,TP03 are baseline versions)
BE      Neighborhood amenities Score 2008
CE      Collective Efficacy Score 2008
PV      Perceived Violence Score 2008
QP      Trust in local agencies Score 2008
TP      Reliance on police Score 2008
hom     Homicide rate per 100,000 population Score 2008-2003 (in log odds)

HomCount2003 Number of homicides in 2003
Pop2003      Population in 2003
HomCount2008 Number of homicides in 2008
Pop2008      Population in 2008
```


```{r}
## These next are equivalent ways to get rates per 1000 from counts
## meddat$HomRate03<-with(meddat, (HomCount2003/Pop2003)*1000)
## meddat$HomRate08<-with(meddat, (HomCount2008/Pop2008)*1000)
meddat<-transform(meddat, HomRate03=(HomCount2003/Pop2003)*1000)
meddat<-transform(meddat, HomRate08=(HomCount2008/Pop2008)*1000)
```

> We tried to make a matched design to counter alternative explanations for
the intervention-versus-non-intervention comparison. We have `nhTrt` as our
intervention or treatment and things measured in 2008 as outcomes with things
measured in 2003 as occuring before the Metrocable was built. The other
variables, measured before the treatment are plausibly covariates.


```{r eval=FALSE}
## Some commands like a formula object:
balfmla<-reformulate(c(names(meddat)[c(5:7,9:24)],"HomRate03"),response="nhTrt")

## Scalar distance on baseline outcome
tmp <- meddat$HomRate03
names(tmp) <- rownames(meddat)
absdist <- match_on(tmp, z = meddat$nhTrt)

## Ordinary Propensity score
glm1<-glm(balfmla,data=meddat,family=binomial)

## Propensity score using elastic net with lambda chosen by cross-validation
library(glmnet)
X <- model.matrix(update(balfmla,~ -1+.),data=meddat)
cv.glmnet1<-cv.glmnet(x=X[,-1],y=meddat$nhTrt,family="binomial",alpha=.5)

## Add scores back to data
meddat$pscore<-predict(glm1) ## linear.predictors not probs
meddat$penpscore<-predict(cv.glmnet1$glmnet.fit,newx=X[,-1],s=cv.glmnet1$lambda.min)

## Make distance matrices
psdist<-match_on(nhTrt~pscore,data=meddat)
penpsdist<-match_on(nhTrt~penpscore,data=meddat)

as.matrix(psdist)[1:5,1:5]
as.matrix(penpsdist)[1:5,1:5]

##  Pictures
par(mfrow=c(1,2))
with(meddat,boxplot(split(pscore,nhTrt)))
with(meddat,boxplot(split(penpscore,nhTrt)))

## Rank-Based Mahalanobis distance (Rosenbaum, Chap 8)
mhdist<-match_on(balfmla,data=meddat,method="rank_mahalanobis")

## Do it
fm1<-fullmatch(IHATEMYJOB,data=meddat) ##, min.controls=1) # min.controls=.5
summary(fm1,data=meddat,min.controls=0,max.controls=Inf)

## Add matched set indicators back to data
meddat$fm1<-NULL
meddat[names(fm1),"fm1"]<-fm1

## We have to show that we have adjusted enough. Did we adjust enough?
newbalfmla <- update(balfmla,.~.+GETMEOUTOFHERESCORE)
xb1<-xBalance(newbalfmla,
	      strata=list(raw=NULL,fm1=~fm1),
	      data=meddat,
	      report=c("std.diffs","z.scores","adj.means",
		       "adj.mean.diffs", "chisquare.test","p.values"))
xb1$overall

## What is the biggest difference within set.
library(dplyr)
diffswithinsets<-meddat %>% group_by(fm1) %>% summarize(meandiff = mean(HomRate03[nhTrt==1]) - mean(HomRate03[nhTrt==0]))
## sapply(split(meddat,meddat$fm1),function(dat){
##	       with(dat,  mean(HomRate03[nhTrt==1]) - mean(HomRate03[nhTrt==0]))
##	      })
summary(diffswithinsets$meandiff)
## Which set is the biggest diff? Which neighborhoods are these?
bigdiff<-diffswithinsets[which.max(diffswithinsets$meandiff),]
meddat[meddat$fm1 == bigdiff$fm1,]

## Diff pre-matching
with(meddat, mean(HomRate03[nhTrt==1]) - mean(HomRate03[nhTrt==0]))

## What are the distances like? 
quantile(as.vector(absdist),seq(0,1,.1))

## CALIPER!! CARZY SETZ!!

caldist <- mhdist + caliper(absdist,1)
as.matrix(absdist)[1:5,1:5]
as.matrix(mhdist)[1:5,1:5]
as.matrix(caldist)[1:5,1:5]

fm2<-fullmatch(MYBOSSSUX,data=meddat,tol=.00001,min.controls=1)

meddat$fm2<-NULL
meddat[names(fm2),"fm2"]<-fm2

xb2<-xBalance(newbalfmla,
	      strata=list(raw=NULL,fm1=~fm1,fm2=~fm2),
	      data=meddat,
	      report=c("std.diffs","z.scores","adj.means",
		       "adj.mean.diffs", "chisquare.test","p.values"))
xb2$overall
xb2$results["HomRate03",,]
xb2$results["pscore",,]
@

# References

